{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-lingual Inference on XNLI Dataset using BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In this notebook, we demostrate using the [Multi-lingual BERT model](https://github.com/google-research/bert/blob/master/multilingual.md) to do language inference in Chinese and Hindi. We use the [XNLI](https://github.com/facebookresearch/XNLI) dataset and the task is to classify sentence pairs into three classes: contradiction, entailment, and neutral.   \n",
    "The figure below shows how [BERT](https://arxiv.org/abs/1810.04805) classifies sentence pairs. It concatenates the tokens in each sentence pairs and separates the sentences by the [SEP] token. A [CLS] token is prepended to the token list and used as the aggregate sequence representation for the classification task.\n",
    "<img src=\"https://nlpbp.blob.core.windows.net/images/bert_two_sentence.PNG\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import shutil\n",
    "\n",
    "nlp_path = os.path.abspath('../../')\n",
    "if nlp_path not in sys.path:\n",
    "    sys.path.insert(0, nlp_path)\n",
    "from utils_nlp.azureml.azureml_utils import get_or_create_workspace\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core import Datastore\n",
    "import azureml.data\n",
    "\n",
    "from azureml.data.azure_storage_datastore import AzureFileDatastore\n",
    "from azureml.train.dnn import PyTorch\n",
    "from azureml.core.runconfig import MpiConfiguration\n",
    "from azureml.core import Experiment\n",
    "from azureml.widgets import RunDetails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations\n",
    "Note that the running time shown in this notebook are on a Standard_NC12 Azure Deep Learning Virtual Machine with two NVIDIA Tesla K80 GPUs. If you want to run through the notebook quickly, you can change the `TRAIN_DATA_USED_PERCENT` to a small number, e.g. 0.01. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# azureml configuration\n",
    "AZUREML_VERBOSE = True\n",
    "cluster_name = \"eval-gpu\"  # Name of AzureML Compute Target cluster\n",
    "\n",
    "# debug flag\n",
    "DEBUG = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace was loaded successfully from the configuration file\n"
     ]
    }
   ],
   "source": [
    "# Let's load the workspace from the configuration file\n",
    "ws = Workspace.from_config()\n",
    "print(\"Workspace was loaded successfully from the configuration file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ws = get_or_create_workspace(\n",
    "    subscription_id=\"<SUBSCRIPTION_ID>\",\n",
    "    resource_group=\"<RESOURCE_GROUP>\",\n",
    "    workspace_name=\"<WORKSPACE_NAME>\",\n",
    "    workspace_region=\"<WORKSPACE_REGION>\",\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Workspace name: {}\".format(ws.name))\n",
    "print(\"Resource group: {}\".format(ws.resource_group))\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: MAIDAPTest\n",
      "Resource group: nlprg\n"
     ]
    }
   ],
   "source": [
    "print(\"Workspace name: {}\".format(ws.name))\n",
    "print(\"Resource group: {}\".format(ws.resource_group))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found compute target: eval-gpu\n",
      "{'currentNodeCount': 0, 'targetNodeCount': 0, 'nodeStateCounts': {'preparingNodeCount': 0, 'runningNodeCount': 0, 'idleNodeCount': 0, 'unusableNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0}, 'allocationState': 'Steady', 'allocationStateTransitionTime': '2019-07-09T16:55:15.003000+00:00', 'errors': None, 'creationTime': '2019-06-25T18:13:14.313025+00:00', 'modifiedTime': '2019-06-25T18:13:30.200677+00:00', 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 4, 'nodeIdleTimeBeforeScaleDown': 'PT120S'}, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_NC6'}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print(\"Found compute target: {}\".format(cluster_name))\n",
    "except ComputeTargetException:\n",
    "    print(\"Creating new compute target: {}\".format(cluster_name))\n",
    "    compute_config = AmlCompute.provisioning_configuration(\n",
    "        vm_size=\"STANDARD_NC6\", max_nodes=1\n",
    "    )\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "    compute_target.wait_for_completion(show_output=True)\n",
    "\n",
    "if AZUREML_VERBOSE:\n",
    "    print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "from utils_nlp.bert.common import Language, Tokenizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# model configurations\n",
    "LANGUAGE = Language.ENGLISH\n",
    "TO_LOWER_CASE = True\n",
    "MAX_SEQ_LENGTH = 128\n",
    "\n",
    "# data configs\n",
    "TEXT_COL = \"text\"\n",
    "LABEL_COL = \"label\"\n",
    "\n",
    "\n",
    "print(\"Create a tokenizer...\")\n",
    "tokenizer= Tokenizer(language=LANGUAGE, to_lower=TO_LOWER_CASE, cache_dir=CACHE_DIR)\n",
    "train_tokens = tokenizer.tokenize(train_df[TEXT_COL])\n",
    "\n",
    "print(\"Tokenize and preprocess text...\")\n",
    "#tokenize\n",
    "train_token_ids, train_input_mask, train_token_type_ids = \\\n",
    "tokenizer.preprocess_classification_tokens(train_tokens, max_len=MAX_SEQ_LENGTH)\n",
    "\n",
    "#preprocess\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels = label_encoder.fit_transform(train_df[LABEL_COL])\n",
    "num_labels = len(np.unique(train_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "type(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input_ids_tensor = torch.tensor(input_ids, dtype=torch.long)\n",
    "input_mask_tensor = torch.tensor(input_mask, dtype=torch.long)\n",
    "#label_ids_tensor = torch.tensor(label_ids, dtype=torch.long)\n",
    "\n",
    "tensor_data = TensorDataset(input_ids_tensor, input_mask_tensor)\n",
    "batch_size = 16\n",
    "DataLoader(tensor_data, sampler, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "type(train_df[LABEL_COL])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from utils_nlp.bert.common import create_data_loader\n",
    "BATCH_SIZE = 16\n",
    "bert_dl = create_data_loader(train_token_ids, train_input_mask,None,  \"random\", batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bert_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 455k/455k [02:45<00:00, 2.75kKB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English training dataset size: 392702\n",
      "                                                text       label\n",
      "0  (Conceptually cream skimming has two basic dim...     neutral\n",
      "1  (you know during the season and i guess at at ...  entailment\n",
      "2  (One of our number will carry out your instruc...  entailment\n",
      "3  (How do you know ? All this is their informati...  entailment\n",
      "4  (yeah i tell you what though if you go price s...     neutral\n"
     ]
    }
   ],
   "source": [
    "#add if makedirs\n",
    "from utils_nlp.dataset.xnli import load_pandas_df\n",
    "TRAIN_DATA_USED_PERCENT = 0.01\n",
    "CACHE_DIR = \"../../temp1\"\n",
    "print(\"load data...\")\n",
    "train_df = load_pandas_df(local_cache_path=CACHE_DIR, file_split=\"train\", language=\"en\")\n",
    "print(\"English training dataset size: {}\".format(train_df.shape[0]))\n",
    "print(train_df.head())\n",
    "train_data_used_count = round(TRAIN_DATA_USED_PERCENT * train_df.shape[0])\n",
    "train_df = train_df.loc[:train_data_used_count]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Conceptually cream skimming has two basic dim...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(you know during the season and i guess at at ...</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(One of our number will carry out your instruc...</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(How do you know ? All this is their informati...</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(yeah i tell you what though if you go price s...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       label\n",
       "0  (Conceptually cream skimming has two basic dim...     neutral\n",
       "1  (you know during the season and i guess at at ...  entailment\n",
       "2  (One of our number will carry out your instruc...  entailment\n",
       "3  (How do you know ? All this is their informati...  entailment\n",
       "4  (yeah i tell you what though if you go price s...     neutral"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create a tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 231508/231508 [00:00<00:00, 1616071.48B/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 3928/3928 [00:01<00:00, 1986.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenize and preprocess text...\n"
     ]
    }
   ],
   "source": [
    "from utils_nlp.bert.common import Language, Tokenizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# model configurations\n",
    "LANGUAGE = Language.ENGLISH\n",
    "TO_LOWER_CASE = True\n",
    "MAX_SEQ_LENGTH = 128\n",
    "\n",
    "# data configs\n",
    "TEXT_COL = \"text\"\n",
    "LABEL_COL = \"label\"\n",
    "\n",
    "print(\"Create a tokenizer...\")\n",
    "tokenizer= Tokenizer(language=LANGUAGE, to_lower=TO_LOWER_CASE, cache_dir=CACHE_DIR)\n",
    "train_tokens = tokenizer.tokenize(train_df[TEXT_COL])\n",
    "\n",
    "print(\"Tokenize and preprocess text...\")\n",
    "#tokenize\n",
    "train_token_ids, train_input_mask, train_token_type_ids = \\\n",
    "tokenizer.preprocess_classification_tokens(train_tokens, max_len=MAX_SEQ_LENGTH)\n",
    "\n",
    "#preprocess\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels = label_encoder.fit_transform(train_df[LABEL_COL])\n",
    "#num_labels = len(np.unique(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3928"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_input_mask[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_token_type_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#len(train_labels)\n",
    "print(train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./entailment_aml\\\\utils_nlp'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_dir = \"./entailment_aml\"\n",
    "if DEBUG and os.path.exists(project_dir): \n",
    "    shutil.rmtree(project_dir) \n",
    "shutil.copytree(\"../../utils_nlp\", os.path.join(project_dir, \"utils_nlp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading ../../temp\\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "Uploading ../../temp\\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.json\n",
      "Uploading ../../temp\\XNLI-MT-1.0.zip\n",
      "Uploading ../../temp\\XNLI-MT-1.0\\.DS_Store\n",
      "Uploaded ../../temp\\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.json, 1 files out of an estimated total of 42\n",
      "Uploading ../../temp\\XNLI-MT-1.0\\multinli\\multinli.train.ar.tsv\n",
      "Uploading ../../temp\\XNLI-MT-1.0\\multinli\\multinli.train.bg.tsv\n",
      "Uploading ../../temp\\XNLI-MT-1.0\\multinli\\multinli.train.de.tsv\n",
      "Uploading ../../temp\\XNLI-MT-1.0\\multinli\\multinli.train.el.tsv\n",
      "Uploaded ../../temp\\XNLI-MT-1.0\\.DS_Store, 2 files out of an estimated total of 42\n",
      "Uploading ../../temp\\XNLI-MT-1.0\\multinli\\multinli.train.en.tsv\n",
      "Uploading ../../temp\\XNLI-MT-1.0\\multinli\\multinli.train.es.tsv\n",
      "Uploading ../../temp\\XNLI-MT-1.0\\multinli\\multinli.train.fr.tsv\n",
      "Uploading ../../temp\\XNLI-MT-1.0\\multinli\\multinli.train.hi.tsv\n",
      "Uploaded ../../temp\\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084, 3 files out of an estimated total of 42\n",
      "Uploading ../../temp\\XNLI-MT-1.0\\multinli\\multinli.train.ru.tsv\n",
      "Uploading ../../temp\\XNLI-MT-1.0\\multinli\\multinli.train.sw.tsv\n",
      "Uploading ../../temp\\XNLI-MT-1.0\\multinli\\multinli.train.th.tsv\n",
      "Uploading ../../temp\\XNLI-MT-1.0\\multinli\\multinli.train.tr.tsv\n",
      "Uploading ../../temp\\XNLI-MT-1.0\\multinli\\multinli.train.ur.tsv\n",
      "Uploading ../../temp\\XNLI-MT-1.0\\multinli\\multinli.train.vi.tsv\n",
      "Uploading ../../temp\\XNLI-MT-1.0\\multinli\\multinli.train.zh.tsv\n",
      "Uploading ../../temp\\XNLI-MT-1.0\\xnli\\.DS_Store\n",
      "Uploading ../../temp\\XNLI-MT-1.0\\xnli\\xnli.dev.en.jsonl\n",
      "Uploading ../../temp\\XNLI-MT-1.0\\xnli\\xnli.dev.en.tsv\n",
      "Uploading ../../temp\\XNLI-MT-1.0\\xnli\\xnli.test.en.jsonl\n",
      "Uploading ../../temp\\XNLI-MT-1.0\\xnli\\xnli.test.en.tsv\n",
      "Uploaded ../../temp\\XNLI-MT-1.0\\xnli\\.DS_Store, 4 files out of an estimated total of 42\n",
      "Uploading ../../temp\\__MACOSX\\._XNLI-MT-1.0\n",
      "Uploading ../../temp\\__MACOSX\\XNLI-MT-1.0\\._.DS_Store\n",
      "Uploading ../../temp\\__MACOSX\\XNLI-MT-1.0\\._multinli\n",
      "Uploading ../../temp\\__MACOSX\\XNLI-MT-1.0\\._xnli\n",
      "Uploaded ../../temp\\__MACOSX\\._XNLI-MT-1.0, 5 files out of an estimated total of 42\n",
      "Uploading ../../temp\\__MACOSX\\XNLI-MT-1.0\\multinli\\._multinli.train.ar.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Retrying (Retry(total=2, connect=3, read=2, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', timeout())': /azureml-filestore-792de9d4-7d0a-464c-b40a-58584f23f5ec/./entailment_aml%5CXNLI-MT-1.0%5Cxnli/xnli.dev.en.tsv?comp=range\n",
      "WARNING - Retrying (Retry(total=2, connect=3, read=2, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', OSError(\"(10054, 'WSAECONNRESET')\",))': /azureml-filestore-792de9d4-7d0a-464c-b40a-58584f23f5ec/./entailment_aml%5CXNLI-MT-1.0%5Cmultinli/multinli.train.ar.tsv?comp=range\n",
      "WARNING - Retrying (Retry(total=2, connect=3, read=2, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', OSError(\"(10054, 'WSAECONNRESET')\",))': /azureml-filestore-792de9d4-7d0a-464c-b40a-58584f23f5ec/./entailment_aml%5CXNLI-MT-1.0%5Cmultinli/multinli.train.tr.tsv?comp=range\n",
      "WARNING - Retrying (Retry(total=2, connect=3, read=2, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', OSError(\"(10054, 'WSAECONNRESET')\",))': /azureml-filestore-792de9d4-7d0a-464c-b40a-58584f23f5ec/./entailment_aml%5CXNLI-MT-1.0%5Cmultinli/multinli.train.th.tsv?comp=range\n",
      "WARNING - Retrying (Retry(total=2, connect=3, read=2, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', timeout())': /azureml-filestore-792de9d4-7d0a-464c-b40a-58584f23f5ec/./entailment_aml%5CXNLI-MT-1.0%5Cxnli/xnli.test.en.jsonl?comp=range\n",
      "WARNING - Retrying (Retry(total=2, connect=3, read=2, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', OSError(\"(10054, 'WSAECONNRESET')\",))': /azureml-filestore-792de9d4-7d0a-464c-b40a-58584f23f5ec/./entailment_aml%5CXNLI-MT-1.0%5Cmultinli/multinli.train.ru.tsv?comp=range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading ../../temp\\__MACOSX\\XNLI-MT-1.0\\multinli\\._multinli.train.bg.tsv\n",
      "Uploaded ../../temp\\__MACOSX\\XNLI-MT-1.0\\._.DS_Store, 6 files out of an estimated total of 42\n",
      "Uploading ../../temp\\__MACOSX\\XNLI-MT-1.0\\multinli\\._multinli.train.de.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Retrying (Retry(total=2, connect=3, read=2, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', OSError(\"(10054, 'WSAECONNRESET')\",))': /azureml-filestore-792de9d4-7d0a-464c-b40a-58584f23f5ec/./entailment_aml%5CXNLI-MT-1.0%5Cxnli/xnli.dev.en.jsonl?comp=range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading ../../temp\\__MACOSX\\XNLI-MT-1.0\\multinli\\._multinli.train.el.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Retrying (Retry(total=2, connect=3, read=2, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', OSError(\"(10054, 'WSAECONNRESET')\",))': /azureml-filestore-792de9d4-7d0a-464c-b40a-58584f23f5ec/./entailment_aml%5CXNLI-MT-1.0%5Cmultinli/multinli.train.sw.tsv?comp=range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded ../../temp\\__MACOSX\\XNLI-MT-1.0\\._multinli, 7 files out of an estimated total of 42\n",
      "Uploading ../../temp\\__MACOSX\\XNLI-MT-1.0\\multinli\\._multinli.train.es.tsv\n",
      "Uploaded ../../temp\\__MACOSX\\XNLI-MT-1.0\\multinli\\._multinli.train.de.tsv, 8 files out of an estimated total of 42\n",
      "Uploaded ../../temp\\__MACOSX\\XNLI-MT-1.0\\._xnli, 9 files out of an estimated total of 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Retrying (Retry(total=2, connect=3, read=2, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', timeout())': /azureml-filestore-792de9d4-7d0a-464c-b40a-58584f23f5ec/./entailment_aml%5CXNLI-MT-1.0%5Cxnli/xnli.test.en.tsv?comp=range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading ../../temp\\__MACOSX\\XNLI-MT-1.0\\multinli\\._multinli.train.fr.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Retrying (Retry(total=2, connect=3, read=2, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', OSError(\"(10054, 'WSAECONNRESET')\",))': /azureml-filestore-792de9d4-7d0a-464c-b40a-58584f23f5ec/./entailment_aml%5CXNLI-MT-1.0%5Cmultinli/multinli.train.es.tsv?comp=range\n",
      "WARNING - Retrying (Retry(total=2, connect=3, read=2, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', OSError(\"(10054, 'WSAECONNRESET')\",))': /azureml-filestore-792de9d4-7d0a-464c-b40a-58584f23f5ec/./entailment_aml%5C__MACOSX%5CXNLI-MT-1.0%5Cmultinli/._multinli.train.es.tsv?comp=range\n",
      "WARNING - Retrying (Retry(total=2, connect=3, read=2, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', OSError(\"(10054, 'WSAECONNRESET')\",))': /azureml-filestore-792de9d4-7d0a-464c-b40a-58584f23f5ec/./entailment_aml%5CXNLI-MT-1.0%5Cmultinli/multinli.train.ur.tsv?comp=range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading ../../temp\\__MACOSX\\XNLI-MT-1.0\\multinli\\._multinli.train.hi.tsv\n",
      "Uploading ../../temp\\__MACOSX\\XNLI-MT-1.0\\multinli\\._multinli.train.ru.tsv\n",
      "Uploaded ../../temp\\__MACOSX\\XNLI-MT-1.0\\multinli\\._multinli.train.fr.tsv, 10 files out of an estimated total of 42\n",
      "Uploaded ../../temp\\__MACOSX\\XNLI-MT-1.0\\multinli\\._multinli.train.ar.tsv, 11 files out of an estimated total of 42\n",
      "Uploaded ../../temp\\__MACOSX\\XNLI-MT-1.0\\multinli\\._multinli.train.hi.tsv, 12 files out of an estimated total of 42\n",
      "Uploading ../../temp\\__MACOSX\\XNLI-MT-1.0\\multinli\\._multinli.train.sw.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Retrying (Retry(total=1, connect=3, read=1, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', timeout())': /azureml-filestore-792de9d4-7d0a-464c-b40a-58584f23f5ec/./entailment_aml%5CXNLI-MT-1.0%5Cxnli/xnli.dev.en.tsv?comp=range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded ../../temp\\XNLI-MT-1.0\\multinli\\multinli.train.fr.tsv, 13 files out of an estimated total of 42\n",
      "Uploaded ../../temp\\XNLI-MT-1.0\\multinli\\multinli.train.en.tsv, 14 files out of an estimated total of 42\n",
      "Uploading ../../temp\\__MACOSX\\XNLI-MT-1.0\\multinli\\._multinli.train.tr.tsv\n",
      "Uploaded ../../temp\\__MACOSX\\XNLI-MT-1.0\\multinli\\._multinli.train.ru.tsv, 15 files out of an estimated total of 42\n",
      "Uploaded ../../temp\\XNLI-MT-1.0\\multinli\\multinli.train.de.tsv, 16 files out of an estimated total of 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Retrying (Retry(total=2, connect=3, read=2, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', OSError(\"(10054, 'WSAECONNRESET')\",))': /azureml-filestore-792de9d4-7d0a-464c-b40a-58584f23f5ec/./entailment_aml%5CXNLI-MT-1.0%5Cmultinli/multinli.train.bg.tsv?comp=range\n",
      "WARNING - Retrying (Retry(total=1, connect=3, read=1, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', timeout())': /azureml-filestore-792de9d4-7d0a-464c-b40a-58584f23f5ec/./entailment_aml%5CXNLI-MT-1.0%5Cmultinli/multinli.train.ar.tsv?comp=range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading ../../temp\\__MACOSX\\XNLI-MT-1.0\\multinli\\._multinli.train.ur.tsv\n",
      "Uploaded ../../temp\\__MACOSX\\XNLI-MT-1.0\\multinli\\._multinli.train.sw.tsv, 17 files out of an estimated total of 42\n",
      "Uploaded ../../temp\\XNLI-MT-1.0\\multinli\\multinli.train.hi.tsv, 18 files out of an estimated total of 42\n",
      "Uploaded ../../temp\\XNLI-MT-1.0\\multinli\\multinli.train.el.tsv, 19 files out of an estimated total of 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Retrying (Retry(total=1, connect=3, read=1, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', timeout())': /azureml-filestore-792de9d4-7d0a-464c-b40a-58584f23f5ec/./entailment_aml%5CXNLI-MT-1.0%5Cmultinli/multinli.train.tr.tsv?comp=range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading ../../temp\\__MACOSX\\XNLI-MT-1.0\\multinli\\._multinli.train.vi.tsv\n",
      "Uploaded ../../temp\\__MACOSX\\XNLI-MT-1.0\\multinli\\._multinli.train.tr.tsv, 20 files out of an estimated total of 42\n",
      "Uploading ../../temp\\__MACOSX\\XNLI-MT-1.0\\multinli\\._multinli.train.zh.tsv\n",
      "Uploaded ../../temp\\__MACOSX\\XNLI-MT-1.0\\multinli\\._multinli.train.ur.tsv, 21 files out of an estimated total of 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Retrying (Retry(total=1, connect=3, read=1, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', timeout())': /azureml-filestore-792de9d4-7d0a-464c-b40a-58584f23f5ec/./entailment_aml%5CXNLI-MT-1.0%5Cmultinli/multinli.train.th.tsv?comp=range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded ../../temp\\__MACOSX\\XNLI-MT-1.0\\multinli\\._multinli.train.bg.tsv, 22 files out of an estimated total of 42\n",
      "Uploaded ../../temp\\__MACOSX\\XNLI-MT-1.0\\multinli\\._multinli.train.vi.tsv, 23 files out of an estimated total of 42\n",
      "Uploaded ../../temp\\__MACOSX\\XNLI-MT-1.0\\multinli\\._multinli.train.zh.tsv, 24 files out of an estimated total of 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Retrying (Retry(total=1, connect=3, read=1, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', timeout())': /azureml-filestore-792de9d4-7d0a-464c-b40a-58584f23f5ec/./entailment_aml%5CXNLI-MT-1.0%5Cmultinli/multinli.train.ru.tsv?comp=range\n",
      "WARNING - Retrying (Retry(total=1, connect=3, read=1, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', timeout())': /azureml-filestore-792de9d4-7d0a-464c-b40a-58584f23f5ec/./entailment_aml%5CXNLI-MT-1.0%5Cxnli/xnli.test.en.jsonl?comp=range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded ../../temp\\__MACOSX\\XNLI-MT-1.0\\multinli\\._multinli.train.es.tsv, 25 files out of an estimated total of 42\n",
      "Uploading ../../temp\\__MACOSX\\XNLI-MT-1.0\\xnli\\._.DS_Store\n",
      "Uploaded ../../temp\\XNLI-MT-1.0\\multinli\\multinli.train.zh.tsv, 26 files out of an estimated total of 42\n",
      "Uploaded ../../temp\\__MACOSX\\XNLI-MT-1.0\\multinli\\._multinli.train.el.tsv, 27 files out of an estimated total of 42\n",
      "Uploaded ../../temp\\__MACOSX\\XNLI-MT-1.0\\xnli\\._.DS_Store, 28 files out of an estimated total of 42\n",
      "Uploaded ../../temp\\XNLI-MT-1.0\\xnli\\xnli.dev.en.jsonl, 29 files out of an estimated total of 42\n",
      "Uploaded ../../temp\\XNLI-MT-1.0\\multinli\\multinli.train.tr.tsv, 30 files out of an estimated total of 42\n",
      "Uploaded ../../temp\\XNLI-MT-1.0\\multinli\\multinli.train.vi.tsv, 31 files out of an estimated total of 42\n",
      "Uploaded ../../temp\\XNLI-MT-1.0\\multinli\\multinli.train.ar.tsv, 32 files out of an estimated total of 42\n",
      "Uploaded ../../temp\\XNLI-MT-1.0\\multinli\\multinli.train.es.tsv, 33 files out of an estimated total of 42\n",
      "Uploaded ../../temp\\XNLI-MT-1.0\\xnli\\xnli.dev.en.tsv, 34 files out of an estimated total of 42\n",
      "Uploaded ../../temp\\XNLI-MT-1.0\\multinli\\multinli.train.ur.tsv, 35 files out of an estimated total of 42\n",
      "Uploaded ../../temp\\XNLI-MT-1.0\\multinli\\multinli.train.sw.tsv, 36 files out of an estimated total of 42\n",
      "Uploaded ../../temp\\XNLI-MT-1.0\\xnli\\xnli.test.en.jsonl, 37 files out of an estimated total of 42\n",
      "Uploaded ../../temp\\XNLI-MT-1.0\\multinli\\multinli.train.ru.tsv, 38 files out of an estimated total of 42\n",
      "Uploaded ../../temp\\XNLI-MT-1.0\\xnli\\xnli.test.en.tsv, 39 files out of an estimated total of 42\n",
      "Uploaded ../../temp\\XNLI-MT-1.0\\multinli\\multinli.train.th.tsv, 40 files out of an estimated total of 42\n",
      "Uploaded ../../temp\\XNLI-MT-1.0\\multinli\\multinli.train.bg.tsv, 41 files out of an estimated total of 42\n",
      "Uploaded ../../temp\\XNLI-MT-1.0.zip, 42 files out of an estimated total of 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_cdd246243450416782214083cc48844e"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datastore_name = \"workspacefilestore\"\n",
    "ds = ws.datastores[datastore_name]\n",
    "\n",
    "# Upload files\n",
    "ds.upload(src_dir=\"../../temp\", target_path=\"./entailment_aml\", overwrite=True, show_progress=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $project_dir/train.py\n",
    "\n",
    "from utils_nlp.bert.sequence_classification import BERTSequenceClassifier\n",
    "from utils_nlp.bert.common import Language, Tokenizer\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import horovod.torch as hvd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import argparse\n",
    "\n",
    "# set random seeds\n",
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "# model configurations\n",
    "LANGUAGE = Language.ENGLISH\n",
    "TO_LOWER_CASE = True\n",
    "MAX_SEQ_LENGTH = 128\n",
    "\n",
    "# training configurations\n",
    "NUM_GPUS = 1\n",
    "BATCH_SIZE = 16 #training batchsize\n",
    "NUM_EPOCHS = 1  # just for debugging! Hong uses 5 in her example\n",
    "\n",
    "# optimizer configurations\n",
    "LEARNING_RATE= 5e-5\n",
    "WARMUP_PROPORTION= 0.1\n",
    "\n",
    "\n",
    "# model configurations\n",
    "LANGUAGE = Language.ENGLISH\n",
    "TO_LOWER_CASE = True\n",
    "MAX_SEQ_LENGTH = 128\n",
    "\n",
    "# data configs\n",
    "TEXT_COL = \"text\"\n",
    "LABEL_COL = \"label\"\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--data_folder', type=str, help='Folder where data is stored')\n",
    "args = parser.parse_args()\n",
    "xnli_folder = os.path.join(args.data_folder, \"entailment_aml\")\n",
    "train_file =  os.path.join(xnli_folder,\"/\")\n",
    "\n",
    "print(\"Create a tokenizer...\")\n",
    "tokenizer= Tokenizer(language=LANGUAGE, to_lower=TO_LOWER_CASE, cache_dir=CACHE_DIR)\n",
    "train_tokens = tokenizer.tokenize(train_df[TEXT_COL])\n",
    "\n",
    "print(\"Tokenize and preprocess text...\")\n",
    "#tokenize\n",
    "train_token_ids, train_input_mask, train_token_type_ids = \\\n",
    "tokenizer.preprocess_classification_tokens(train_tokens, max_len=MAX_SEQ_LENGTH)\n",
    "\n",
    "#preprocess\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels = label_encoder.fit_transform(train_df[LABEL_COL])\n",
    "num_labels = len(np.unique(train_labels))\n",
    "\n",
    "#for training split data on workers\n",
    "\n",
    "print(\"Create classifier...\")\n",
    "classifier = BERTSequenceClassifier(language=LANGUAGE,\n",
    "                                    num_labels=num_labels,\n",
    "                                    cache_dir=CACHE_DIR)\n",
    "        \n",
    "print(\"Finetune classifier...\")\n",
    "\n",
    "classifier.fit(token_ids=train_token_ids,\n",
    "               input_mask=train_input_mask,\n",
    "               token_type_ids=train_token_type_ids,\n",
    "               labels=train_labels_tensor,\n",
    "               num_gpus=NUM_GPUS,\n",
    "               num_epochs=NUM_EPOCHS,\n",
    "               batch_size=BATCH_SIZE,\n",
    "               lr=LEARNING_RATE,\n",
    "               warmup_proportion=WARMUP_PROPORTION)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_params = {\n",
    "    \"--data_folder\": ds.as_mount(),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = PyTorch(\n",
    "    source_directory=project_dir,\n",
    "    compute_target=compute_target,\n",
    "    script_params=script_params,\n",
    "    entry_script=\"train.py\",\n",
    "    node_count=2,\n",
    "    distributed_training=MpiConfiguration(),\n",
    "    use_gpu=True,\n",
    "    framework_version=\"1.0\",\n",
    "    conda_packages=[\"scikit-learn=0.20.3\", \"numpy\", \"spacy\", \"nltk\"],\n",
    "    pip_packages=[\"pandas\", \"pytorch-pretrained-bert\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "experiment = Experiment(ws, name=\"entail-bert-xnli\")\n",
    "run = experiment.submit(est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.cancel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_hindi = classifier_multi.predict(token_ids=test_token_ids_hindi,\n",
    "                                             input_mask=test_input_mask_hindi,\n",
    "                                             token_type_ids=test_token_type_ids_hindi,\n",
    "                                             batch_size=BATCH_SIZE)\n",
    "print(\"Prediction time : {:.3f} hrs\".format(t.interval / 3600))\n",
    "predictions_hindi= label_encoder_hindi.inverse_transform(predictions_hindi)\n",
    "print(classification_report(test_df_hindi[LABEL_COL], predictions_hindi))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
